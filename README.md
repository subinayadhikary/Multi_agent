# ArguGenCourt: Courtroom Argument Generation using Judicial Multi-agent Large Language Models
In this paper, we consider solely legal cases from the ***U.S. Supreme Court*** and evaluate the performance of Large Language Models (LLMs) in generating courtroom arguments utilizing different approaches, including zero-shot, and few-shot within a multi-agent setup, called ***ArguGenCourt***.
# 1. Workflow of ArguGenCourt:
<img src= "https://github.com/user-attachments/assets/ea34062a-bd1b-4af8-86d4-afcda4b7a26b"> <br />
In this work on LLM-based multi-agent conversation, the ***judge agent*** communicates with the ***petitioner*** and ***respondent***, based on the provided details of the case. Later, we evaluate the arguments generated by the ***petitioner*** and ***respondent*** agent using existing metrics (e.g., Bert-score) in comparison with real-life courtroom arguments.
# 2. Methods of Utterance Selection:
![Image](https://github.com/user-attachments/assets/3a5cea0d-a6d5-433e-8a3e-9d684c77c091) <br/>
We show that, for selecting the utterances from the same document, we explore two approaches: ***random selection*** (ad-hoc) and ***score-based selection***. In the score-based selection, we provide the case-specific closest utterances as examples in the first round conversation, depending on the similarity score between generated arguments and real-life arguments, termed as ***guided few-shot***. Subsequently, ***ArguGenCourt*** produces two sets of arguments: one between judge and petitioner and the other between judge and respondent agent. Finally, we evaluate the generated arguments for both the petitioner and respondent.
